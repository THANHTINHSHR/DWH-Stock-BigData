FROM openjdk:11

# Install pip
RUN apt-get update && \
    apt-get install -y python3 python3-pip && \
    apt-get clean

# Config environment
ENV JAVA_HOME=/usr/local/openjdk-11
ENV PYSPARK_PYTHON=python3
ENV HADOOP_HOME=/opt/hadoop
ENV PYTHONPATH=/app
ENV SPARK_HOME=/opt/spark-dist
ENV PATH="$SPARK_HOME/bin:$PATH"

# install python packages
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install PySpark
COPY ./tar/spark-3.5.6-bin-hadoop3.tgz /tar/
RUN mkdir -p /opt/spark-dist && tar -xzf /tar/spark-3.5.6-bin-hadoop3.tgz -C /opt/spark-dist --strip-components=1

# Copy Jars
COPY ./jars/*.jar /opt/spark/jars/


# Copy source code
COPY ./core ./core
COPY log4j.properties /opt/spark-dist/conf/log4j.properties
CMD ["python3", "core/streaming/run_streaming.py"]
