-----------Chuẩn bị đầu vào cho AI-----------
- chuyển đổi đầu vào cho Ai, từ s3 sang, nhưng muốn nhìn thấy nó các xử thí nneen xài csv lưu trung gian xem nhưng lại 
 bị lỗi, phải dùng parquet, nhưng như vậy thì không thấy nội dung df thay đổi nữa. coi như mù chút
 - đầu vào xong, làm 1 lúc rồi cho đầu ra encode nhưng vướn chổ mình chọn cái chuẩn hóa sai rồi, không biết thoogn tin sao àm giải mã.
 - Làm lại, làm nhhuw này thì đầu ra biết coin nào là coin nào ?, cần cachs tieps caanu kahcs như chia dữ liệu đầu vào ra.
 - Y trong tensor đầu vào bi thay đổi co cơ chế bên trong nn.modelm ...........chán quá, bỏ batch
 - lỗi tui dc chưa, do tui truyền ko đúng thứ tự nên bị hiểu nhẩm khi lấy giá trị khi thực hiện evaluate trong train.
 - -------------------- Luồng module----------
 đầu tiên là 1 cái trigger để tạo các file bộ não pth., sau khi tạo xong mới dùng các file đó huấn luyện mô hình
 vì mình thiết kế mô hình của mình huấn luyện đồng thời có trình tự nhiều symbol nên có hơi khác với các truyền vào và xài lại method.
 -----chọn đầu ra -----
-Vì batch nên đưa lên s3, sau đó -athena-superset, 
-Tuy nhiên superset ko hỗ trợ time-series nên đưa 1 nhánh nữa là lên influxDB -> Grafana ( cần xóa trc khi đưa lên để tránh trùng lặp dữ lieeuh)
Nói chung là vì modul trc đã làm r nên h làm rất dễ!.
- --------------- Xây dựng bộ nhớ AI -----------------
- Tiến hành clone nhánh của modul ETL trướ đó để chạy trong vòng hai ngày liên tục để thu thập dữ liệu, tiens hành tính toán
- Tính sơ bộ :
    Dự đoán 5 phút tiếp theo → pred_len = 5 × 60 = 300

    Input đầu vào dài 15 phút → seq_len = 15 × 60 = 900

    seq_len = 900

    pred_len = 300

    Tỉ lệ pred / seq = 1/3 → ✅ hợp lý

với tốc độ thu thập dữ liệu mỗi 1dir chứa dữ liệu 10-20s 
thì cần đâu đó khảng hơn 10000 dir nên mình cho chạy nguyên ngày luôn